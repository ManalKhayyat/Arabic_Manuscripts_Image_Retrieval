{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras, os\n",
    "from keras import Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix,f1_score,recall_score,precision_score\n",
    "from keras.models import Model, load_model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import datetime\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 64\n",
    "batch_size = 64\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "nb_epochs = 10\n",
    "\n",
    "datagen = ImageDataGenerator()  # set validation split\n",
    "arabic_data = datagen.flow_from_directory(\n",
    "    'arabic',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,shuffle=False)  # set as training data\n",
    "class_indices_flipped = {v: k for k, v in arabic_data.class_indices.items()}\n",
    "# Step 1 Train the VGG Model to classify the manuscript\n",
    "arabic_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_local():\n",
    "    base_model = VGG19(weights='imagenet',\n",
    "                       include_top=False)  # imports the Vgg19 model and discards the last 1000 neuron layer.\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='sigmoid')(\n",
    "        x)  # we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "    x = Dense(1024, activation='sigmoid')(x)  # dense layer 2\n",
    "    x = Dense(512, activation='sigmoid')(x)  # dense layer 3\n",
    "    preds = Dense(64, activation='softmax')(x)  # final layer with softmax activation\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=preds)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model_local()\n",
    "model.compile(optimizer='Adam', loss='weighted_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we need to use a penultimate layer\n",
    "new_model = Model(model.inputs, model.layers[-2].output)\n",
    "new_model.compile(optimizer='Adam', loss='weighted_categorical_crossentropy', metrics=['accuracy'])\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_model.predict_generator(arabic_data, len(arabic_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape # 8368,512\n",
    "Y= arabic_data.classes\n",
    "\n",
    "#Number of similar pages to retrieve\n",
    "K = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = np.array(arabic_data.filenames)\n",
    "filepaths = np.array(arabic_data.filepaths)\n",
    "data = {'filenames': filenames, 'filepaths' : filepaths, 'manuscriptID': Y}\n",
    "new_df = pd.DataFrame(data)\n",
    "\n",
    "new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(path):\n",
    "    image = load_img(path, target_size=(224, 224))\n",
    "    return np.array(image).reshape(1,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now().timestamp()\n",
    "\n",
    "total_accuracy = 0\n",
    "Y_pred_list = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for key,image_path in new_df['filepaths'].iteritems():\n",
    "    #Get the predicted feature vector for the given image\n",
    "    pred_feature_vec = new_model.predict(get_input(image_path))\n",
    "    \n",
    "    #Find the cosine similarity array based on all the feature vectors \n",
    "    #stored in X\n",
    "    similarity_array = cosine_similarity(pred_feature_vec, X)[0]\n",
    "    \n",
    "    #Get top K indices \n",
    "    indices = similarity_array.argsort()[-K:][::-1]\n",
    "    \n",
    "    true_ID = new_df['manuscriptID'].loc[key]\n",
    "    total_pages = new_df[ new_df['manuscriptID'] == true_ID]['filenames'].count()\n",
    "    predicted_arr = new_df['manuscriptID'].loc[indices].values\n",
    "    \n",
    "    Y_pred_list.append(predicted_arr[0])\n",
    "    \n",
    "    #Number of correct predictions out of K\n",
    "    found = np.count_nonzero(predicted_arr == true_ID)\n",
    "    #print(indices)    \n",
    "    if total_pages >= K:\n",
    "        total_accuracy +=  found/K\n",
    "    else:\n",
    "        #total_pages is less than K\n",
    "        total_accuracy += found/total_pages\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count > 0 and count % 100 == 0:\n",
    "        print(\"Done \", count)\n",
    "        print(\"Accuracy so far %g %%\" % (total_accuracy/count * 100))\n",
    "       \n",
    "end_time =  datetime.datetime.now().timestamp()\n",
    "total_retrieval_time = end_time - start_time #In Seconds\n",
    "print(\"Total retrieval time %g seconds\" % total_retrieval_time)\n",
    "\n",
    "mean_accuracy = total_accuracy/new_df.shape[0]\n",
    "print(\"\\nThe mean accuracy for top %d images is %g %%\" % (K, mean_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y, Y_pred_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the confusion matrix\n",
    "#Note that Y_pred_list contains the top prediction\n",
    "sn.heatmap(confusion_matrix(Y, Y_pred_list), cmap=plt.cm.Blues, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Manuscript ID')\n",
    "plt.ylabel('True Manuscript ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix above does not have a single false positive. So the top predicted class is always predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_score(Y, Y_pred_list,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(Y, Y_pred_list,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(Y, Y_pred_list,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_image_path = \"*/arabic/3/DSC00009.JPG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now().timestamp()\n",
    "output = new_model.predict(get_input(query_image_path)) # VGG Model - 512\n",
    "similarity_array = cosine_similarity(output, X)[0]\n",
    " \n",
    "#Get top K indices \n",
    "indices = similarity_array.argsort()[-10:][::-1]\n",
    "end_time =  datetime.datetime.now().timestamp()\n",
    "\n",
    "total_retrieval_time = end_time - start_time #In Seconds\n",
    "total_retrieval_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filenames[indices])\n",
    "similarity_array[similarity_array.argsort()[-10:][::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
