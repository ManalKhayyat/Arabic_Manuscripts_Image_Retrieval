{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "_qpyveO-P7hn",
    "outputId": "984989e2-4205-42fe-cf08-246bacd4e162"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras \n",
    "import tensorflow as tf \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, GlobalMaxPooling1D, Bidirectional\n",
    "from keras.layers import Dropout, GRU, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90EKiOcuP7im"
   },
   "outputs": [],
   "source": [
    "cleaned_text_path  = \"*/cleaned-text/\"\n",
    "OUTPUT_LENGTH=64 # Size of Author List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "suELBT_cP7iy",
    "outputId": "6ec1b51d-e66a-4b7b-9b97-6014ef37fff1"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "entries = []\n",
    "for i in range(64):\n",
    "    for file_name in glob.glob(cleaned_text_path+str(i+1)+\"/*.cleaned.txt\"):\n",
    "        entries.append({\"content\":open(file_name, encoding='utf-8').read(),\"label\":str(i+1), \"file_path\": file_name})\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qpJRuK7BP7jA",
    "outputId": "565fa13a-e9f8-4d75-ea99-ade5ce90d379"
   },
   "outputs": [],
   "source": [
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "uqrfeK-eP7jM",
    "outputId": "171cedca-730d-457e-b30e-5dce69276cba"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(entries)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a9PUw890P7jW",
    "outputId": "042011d2-dd4f-4472-9c64-946a45fae7d8"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Cunrw3kcP7jg",
    "outputId": "421ef1b2-e4f4-458b-a064-084ff1f90666"
   },
   "outputs": [],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', \n",
    "                      lower=True, oov_token=\"UNK\")\n",
    "\n",
    "tokenizer.fit_on_texts(df['content'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1rjLlM8YP7jp"
   },
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    \n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape =(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape =(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "id": "yYgWLnr9P7jz",
    "outputId": "33b16034-c2d7-4c41-979d-3ea1fca1aa9d"
   },
   "outputs": [],
   "source": [
    "#### Textual model code with attention\n",
    "textual_model = Sequential()\n",
    "textual_model.add(Embedding(MAX_NB_WORDS, \n",
    "                    100,  \n",
    "                    input_length=MAX_SEQUENCE_LENGTH, input_shape=(500, )))\n",
    "\n",
    "textual_model.add(SpatialDropout1D(0.3))\n",
    "textual_model.add(Bidirectional(LSTM(64, dropout=0.5, recurrent_dropout=0.5, return_sequences=True)))\n",
    "textual_model.add(Attention(MAX_SEQUENCE_LENGTH))\n",
    "textual_model.add(Dropout(0.5))\n",
    "textual_model.add(BatchNormalization())\n",
    "\n",
    "textual_model.add(Dense(OUTPUT_LENGTH, activation='softmax'))\n",
    "textual_model.compile(loss='weighted_categorical_crossentropy', optimizer=Adam(learning_rate=0.000001), metrics=['accuracy'])\n",
    "textual_model.load_weights(\"manuscript_lstm.hdf5\")\n",
    "print(textual_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZq5alrLP7kG"
   },
   "outputs": [],
   "source": [
    "textual_model_int = Model(inputs=textual_model.input, outputs=textual_model.layers[-4].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNZhLYu8P7kR"
   },
   "outputs": [],
   "source": [
    "# VGG Stuff\n",
    "import keras, os\n",
    "from keras import Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7i4-9z7P7ka"
   },
   "outputs": [],
   "source": [
    "# Generate the Visual model with all layers (with top)\n",
    "def build_model_local():\n",
    "    base_model = VGG19(weights='imagenet',\n",
    "                       include_top=False, input_shape=(None, None, 3))  # imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='sigmoid')(x)  # we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "    x = Dense(1024, activation='sigmoid')(x)  # dense layer 2\n",
    "    x = Dense(512, activation='sigmoid')(x)  # dense layer 3\n",
    "    preds = Dense(OUTPUT_LENGTH, activation='softmax')(x)  # final layer with softmax activation\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=preds)\n",
    "    return model\n",
    "\n",
    "\n",
    "visual_model = build_model_local()\n",
    "visual_model.compile(optimizer=Adam(), loss='weighted_categorical_crossentropy', metrics=['accuracy'])\n",
    "visual_model.load_weights(\"manuscript_visual.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gx6ykXNCQF15"
   },
   "outputs": [],
   "source": [
    "visual_model_int = Model(inputs=visual_model.input, outputs=visual_model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QY71dSWkP7ki",
    "outputId": "8be29e53-3058-4db0-94d7-61d3599a8671"
   },
   "outputs": [],
   "source": [
    "visual_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxwPvCB2P7kt"
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "images = []\n",
    "for i in range(64):\n",
    "    for f_n in glob.glob(\"*/arabic/\" + str(i + 1) + '/*'):\n",
    "        images.append({\n",
    "            \"image_path\":f_n,\n",
    "            \"text_path\":f_n.replace(\"arabic\",\"cleaned-text\")+\".txt.cleaned.txt\",\n",
    "            \"label\":i\n",
    "        })\n",
    "\n",
    "shuffle(images)\n",
    "images_train = images[:7000]\n",
    "images_validation = images[7000:8000]\n",
    "images_test = images[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBRfVnw5TfhT"
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WeAeqKh3SoKz"
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "images = []\n",
    "\n",
    "for i in range(64):\n",
    "  for f_n in glob.glob(file_path + \"/\" + str(i + 1) + \"/*.JPG\"):\n",
    "    images.append({\n",
    "        \"image_path\": f_n,\n",
    "        \"text_path\": f_n + \".txt.cleaned.txt\",\n",
    "        \"label\": i\n",
    "    })\n",
    "\n",
    "shuffle(images)\n",
    "images_train = images[:7000]\n",
    "images_validation = images[7000:8000]\n",
    "images_test = images[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "wVIRua8X4_kb",
    "outputId": "0487b180-3f1b-47ed-ab2a-43b37cfe8663"
   },
   "outputs": [],
   "source": [
    "images_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hMZEgp1qRcN_",
    "outputId": "e28e131e-1f1f-4c62-ef1d-ef59aaf499bf"
   },
   "outputs": [],
   "source": [
    "len(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G6qPfiBuypDt",
    "outputId": "e8f5fc26-188c-40e9-8e3f-098aebda0549"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6CRsRR_P7k2",
    "outputId": "df7a67f5-ab6e-47c1-a4a5-a30031ad2c88"
   },
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mIjdGV8EP7k-",
    "outputId": "377e0302-33c5-482d-9d86-46c1c3737444"
   },
   "outputs": [],
   "source": [
    "len(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7hqkcXZUP7lH"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "# Load an image from file\n",
    "def get_input(path):\n",
    "    image = load_img(path, target_size=(224, 224))\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKz6jkRgP7lT"
   },
   "outputs": [],
   "source": [
    "class My_Generator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, img_txt_objs , batch_size):\n",
    "        self.img_txt_objs = img_txt_objs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.img_txt_objs) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        batch_objs = self.img_txt_objs[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        batch_input_1 = []\n",
    "        batch_input_2 = []\n",
    "        batch_output = []\n",
    "\n",
    "        for obj in batch_objs:\n",
    "            \n",
    "            input1 = get_input(obj[\"image_path\"])\n",
    "            \n",
    "            content = open(obj[\"text_path\"], encoding='utf-8').read()            \n",
    "            input2 = tokenizer.texts_to_sequences([content.strip()])\n",
    "            input2 = pad_sequences(input2, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\").reshape(500)\n",
    "\n",
    "            \n",
    "            one_hot = np.zeros(OUTPUT_LENGTH)\n",
    "            one_hot[obj[\"label\"]] = 1\n",
    "            \n",
    "            batch_input_1.append(input1)            \n",
    "            batch_input_2.append(input2)\n",
    "            batch_output.append(one_hot)\n",
    "            \n",
    "        return [np.array(batch_input_1), np.array(batch_input_2) ], np.array(batch_output)\n",
    "\n",
    "test_image_gen = My_Generator(images_test, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lEUyJ9SISKf5",
    "outputId": "3ce61015-94e3-44ba-9d5d-afda2f79c188"
   },
   "outputs": [],
   "source": [
    "images_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "PJQrqtTiP7lo",
    "outputId": "10bd9e1e-374d-4a85-e284-81b34c9b277c"
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "# Features-level fusion model\n",
    "\n",
    "input_1 = Input(shape=(224, 224, 3))\n",
    "input_2 =  Input(shape=(500,))\n",
    "\n",
    "x1 = visual_model_int(input_1)\n",
    "x2 = textual_model_int(input_2)\n",
    "\n",
    "x = Concatenate(axis=-1)([x1,x2])\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "out = Dense(OUTPUT_LENGTH, activation=\"softmax\")(x)\n",
    "model = Model([input_1, input_2], out)\n",
    "\n",
    "model.compile(loss='weighted_categorical_crossentropy', optimizer=Adam(learning_rate=0.000001), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "566hUfnJP7l4"
   },
   "outputs": [],
   "source": [
    "len(images_test)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzvsU4oWP7l9"
   },
   "outputs": [],
   "source": [
    "filepath=\"weights_fusion_manuscript_v2.hdf5\"\n",
    "batch_size= 32\n",
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lK9zo3jVP7mE",
    "outputId": "bde71fed-b8fb-4d51-eb8c-dec6ebdf2571"
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(probabilities, axis=1)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lExaD5kxP7mM",
    "outputId": "2a45d017-61f2-453b-eac3-c04714c2708f"
   },
   "outputs": [],
   "source": [
    "y_true = [i['label'] for i in images_test]\n",
    "len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlEKp1i0P7mU",
    "outputId": "c8e9586f-6e9e-4a14-bd00-6a2c7007a1f1"
   },
   "outputs": [],
   "source": [
    "y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2-59HEuP7mb",
    "outputId": "fe40cf13-f99f-490a-b940-f6bce525b252"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,recall_score,precision_score,average_precision_score\n",
    "\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJYtzUx1P7mi",
    "outputId": "923e5ded-9ada-4970-cf87-5599973bb1a8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lk9xjhbdP7mp",
    "outputId": "d49f3676-8fd0-4314-d2b3-0e98a9ac37c6"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-PQlkf5P7mt",
    "outputId": "d29fa47f-1976-493d-d72d-112038a17131"
   },
   "outputs": [],
   "source": [
    "precision_score(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2ZH_ILWP7m2",
    "outputId": "18a214db-1633-49ea-d5e8-6e9289fddf58"
   },
   "outputs": [],
   "source": [
    "recall_score(y_true, y_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sleqzNLGP7m8",
    "outputId": "ad2d89bb-afb5-4055-c22c-25e0be7d9e46"
   },
   "outputs": [],
   "source": [
    "f1_score(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQ0x1JD9P7nM"
   },
   "outputs": [],
   "source": [
    "X_feature = model.predict_generator(test_image_gen, steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QJjWoIJP7nU"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "entries = []\n",
    "filenames =[]\n",
    "for i in range(64):\n",
    "    for file_name in glob.glob(cleaned_text_path+str(i+1)+\"/*.cleaned.txt\"):\n",
    "        print(file_name)\n",
    "        filenames.append(file_name)\n",
    "        entries.append({\n",
    "            \"content\":open(file_name, encoding='utf-8').read(),\n",
    "            \"label\":str(i+1),\n",
    "            \"filepaths\":file_name,\n",
    "            \"manuscriptID\":str(i+1),\n",
    "        })\n",
    "filenames = np.array(filenames)\n",
    "df = pd.DataFrame(entries)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LpcFqGSPU9yi",
    "outputId": "04f98571-09d8-41ac-a011-c7cc81bec575"
   },
   "outputs": [],
   "source": [
    "df.head(1)['filepaths'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QepcHxSpP7nZ"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "K = 10\n",
    "start_time = datetime.datetime.now().timestamp()\n",
    "\n",
    "total_accuracy = 0\n",
    "Y_pred_list = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for key,image_path in df['filepaths'].iteritems():\n",
    "    #Get the predicted feature vector for the given image\n",
    "    content = open(image_path, encoding='utf-8').read()\n",
    "    X_Q = tokenizer.texts_to_sequences([content])\n",
    "    X_Q = pad_sequences(X_Q, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "    pred_feature_vec =  model.predict(X_Q) \n",
    "    \n",
    "    #Find the cosine similarity array based on all the feature vectors \n",
    "    #stored in X\n",
    "    similarity_array = cosine_similarity(pred_feature_vec,X_feature)[0]\n",
    "    \n",
    "    #Get top K indices \n",
    "    indices = similarity_array.argsort()[-K:][::-1]\n",
    "    \n",
    "    true_ID = df['manuscriptID'].loc[key]\n",
    "    total_pages = df[ df['manuscriptID'] == true_ID]['filepaths'].count()\n",
    "    predicted_arr = df['manuscriptID'].loc[indices].values\n",
    "    \n",
    "    Y_pred_list.append(predicted_arr[0])\n",
    "    \n",
    "    #Number of correct predictions out of K\n",
    "    found = np.count_nonzero(predicted_arr == true_ID)\n",
    "    #print(indices)    \n",
    "    if total_pages >= K:\n",
    "        total_accuracy +=  found/K\n",
    "    else:\n",
    "        #total_pages is less than K\n",
    "        total_accuracy += found/total_pages\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count > 0 and count % 100 == 0:\n",
    "        print(\"Done \", count)\n",
    "        print(\"Accuracy so far %g %%\" % (total_accuracy/count * 100))\n",
    "       \n",
    "end_time =  datetime.datetime.now().timestamp()\n",
    "total_retrieval_time = end_time - start_time #In Seconds\n",
    "print(\"Total retrieval time %g seconds\" % total_retrieval_time)\n",
    "\n",
    "mean_accuracy = total_accuracy/df.shape[0]\n",
    "print(\"\\nThe mean accuracy for top %d images is %g %%\" % (K, mean_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHIk06aYP7ne"
   },
   "outputs": [],
   "source": [
    "query_text_file  = \"*/cleaned-text/2/DSC00009.JPG.txt.cleaned.txt\"\n",
    "content = open(query_text_file, encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sfBZ2i2vP7nk"
   },
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now().timestamp()\n",
    "output = new_model.predict(X_Q) \n",
    "similarity_array = cosine_similarity(output, X_feature)[0]\n",
    " \n",
    "#Get top K indices \n",
    "indices = similarity_array.argsort()[-20:][::-1]\n",
    "end_time =  datetime.datetime.now().timestamp()\n",
    "\n",
    "total_retrieval_time = end_time - start_time #In Seconds\n",
    "total_retrieval_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdcI9pdCP7nn"
   },
   "outputs": [],
   "source": [
    "print(filenames[indices])\n",
    "similarity_array[similarity_array.argsort()[-20:][::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ent6dV8ozMDd"
   },
   "outputs": [],
   "source": [
    "text_model_preds = textual_model.predict_generator(generator=test_image_gen, steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7skk_FeoUEPx"
   },
   "outputs": [],
   "source": [
    "test_images_list = list(test_image_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4R3XnHwUJmq"
   },
   "outputs": [],
   "source": [
    "test_images_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "FsSumm4DltVt",
    "outputId": "b0c977fe-1b08-4297-9555-3f5054dbf514"
   },
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4WxMFo0VGjz"
   },
   "outputs": [],
   "source": [
    "# Images_test\n",
    "\n",
    "def get_dataset(images_obj):\n",
    "\n",
    "  image_test_data = []\n",
    "  content_test_data = []\n",
    "  output_test_data = []\n",
    "\n",
    "  for index, obj in enumerate(images_obj):\n",
    "\n",
    "    input1 = get_input(obj[\"image_path\"])\n",
    "                \n",
    "    # content = open(obj[\"text_path\"], encoding='utf-8').read()\n",
    "    content =   df.loc[df.file_path == obj[\"text_path\"], 'content'].values.tolist()[0]        \n",
    "    input2 = tokenizer.texts_to_sequences([content.strip()])\n",
    "    input2 = pad_sequences(input2, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\").reshape(500)\n",
    "\n",
    "\n",
    "    one_hot = np.zeros(OUTPUT_LENGTH)\n",
    "    one_hot[obj[\"label\"]] = 1\n",
    "\n",
    "    if index % 100 == 0:\n",
    "      print(index)\n",
    "\n",
    "    image_test_data.append(input1)\n",
    "    content_test_data.append(input2)\n",
    "    output_test_data.append(one_hot)\n",
    "\n",
    "  return image_test_data, content_test_data, output_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XZ-_OnfqG17g",
    "outputId": "40309033-6d69-4437-9a01-40e54bb9c57f"
   },
   "outputs": [],
   "source": [
    "images_train_data, content_train_data, output_train_data = get_dataset(images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9QE6QPAiUnS"
   },
   "outputs": [],
   "source": [
    "images_validation_data, content_validation_data, output_validation_data = get_dataset(images_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "GBU6n4tLNr1-",
    "outputId": "2a70b98d-0c55-493d-c5f6-28b83b74fea6"
   },
   "outputs": [],
   "source": [
    "image_test_data, content_test_data, output_test_data = get_dataset(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lv5rMrf-pY8N",
    "outputId": "c5b766cf-6706-47ed-a0bc-38267db483c3"
   },
   "outputs": [],
   "source": [
    "len(images_validation_data), len(content_validation_data), len(output_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q3GHf3dhVh17",
    "outputId": "9c4317c7-9646-4898-8a41-2e9d2390e207"
   },
   "outputs": [],
   "source": [
    "len(image_test_data), len(content_test_data), len(output_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gftPDcMnJZGM"
   },
   "outputs": [],
   "source": [
    "def get_tanh_normalized_score(input_value_preds):\n",
    "  # TanH normalized probability scores\n",
    "  score = 0.5*(np.tanh(0.5*(input_value_preds - np.mean(input_value_preds, axis=0)) / np.std(input_value_preds, axis=0)) + 1)\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5mwvOcOYxIW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,recall_score,precision_score,average_precision_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Yv4y9Nyzijf"
   },
   "outputs": [],
   "source": [
    "def get_correction_score(y_true_one_hot, y_pred_probs, is_one_hot=False):\n",
    "  if is_one_hot:\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "  else:\n",
    "    y_pred = y_pred_probs\n",
    "\n",
    "  if is_one_hot:\n",
    "    y_true = np.argmax(y_true_one_hot, axis=1)\n",
    "  else:\n",
    "    y_true = y_true_one_hot\n",
    "\n",
    "  print(y_pred)\n",
    "  print(y_true)\n",
    "\n",
    "  print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "  print(classification_report(y_true, y_pred))\n",
    "\n",
    "  print('accuracy = ',accuracy_score(y_true, y_pred))\n",
    "  print('precision = ', precision_score(y_true, y_pred, average='weighted'))\n",
    "  print('recall = ', recall_score(y_true, y_pred,average='weighted'))\n",
    "  print('f1 score = ', f1_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-teTKh5bXdad"
   },
   "outputs": [],
   "source": [
    "text_data_probs = textual_model.predict(np.array(content_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RlXEjlr2Xwsb"
   },
   "outputs": [],
   "source": [
    "image_data_probs = visual_model.predict(np.array(image_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wP47RyvfdARx"
   },
   "outputs": [],
   "source": [
    "text_train_data_probs = textual_model.predict(np.array(content_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcUeP5bwdGGZ"
   },
   "outputs": [],
   "source": [
    "image_train_data_probs = visual_model.predict(np.array(images_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O7gyx8xj6RXR"
   },
   "outputs": [],
   "source": [
    "text_train_score = get_tanh_normalized_score(text_train_data_probs)\n",
    "image_train_score = get_tanh_normalized_score(image_train_data_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Na6rvNBP6v4a"
   },
   "outputs": [],
   "source": [
    "train_sum_rule_score = np.sum([text_train_score, image_train_score], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_yzBiVt6d_T"
   },
   "outputs": [],
   "source": [
    "text_test_score = get_tanh_normalized_score(text_data_probs)\n",
    "image_test_score = get_tanh_normalized_score(image_data_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnCGbtjY68EA"
   },
   "outputs": [],
   "source": [
    "test_sum_rule_score = np.sum([text_test_score, image_test_score], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-YpRgJa6nfd"
   },
   "outputs": [],
   "source": [
    "train_output = np.argmax(output_train_data, axis=1)\n",
    "test_output = np.argmax(output_test_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JF_mB6GS7Bnq"
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "# Score-level fusion model\n",
    "\n",
    "input_1 = Input(shape=(224, 224, 3))\n",
    "input_2 =  Input(shape=(500,))\n",
    "\n",
    "x1 = text_test_score\n",
    "x2 = image_test_score\n",
    "\n",
    "x = test_sum_rule_score([x1,x2])\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "out = Dense(OUTPUT_LENGTH, activation=\"softmax\")(x)\n",
    "model = Model([input_1, input_2], out)\n",
    "\n",
    "model.compile(loss='weighted_categorical_crossentropy', optimizer=Adam(learning_rate=0.000001), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZdLyYssJ7UdJ",
    "outputId": "069ddcbf-e93b-498b-ff45-b0b633cc5ed1"
   },
   "outputs": [],
   "source": [
    "get_correction_score(test_output, clf.predict(test_min_rule_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pp1H2cttX7Lr"
   },
   "outputs": [],
   "source": [
    "## Scores of text_data_probs, and score of image_data_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yKinNvbJZsuW",
    "outputId": "241d7ae9-b8d4-4220-f6db-7c30b0620fc4"
   },
   "outputs": [],
   "source": [
    "get_correction_score(output_test_data, text_data_probs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "V5TB7HszZxEM",
    "outputId": "1344845d-5929-4223-a4b7-de8277466036"
   },
   "outputs": [],
   "source": [
    "get_correction_score(output_test_data, image_data_probs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1stF4dIpnBue"
   },
   "outputs": [],
   "source": [
    "## Similarity scores fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZ5Y9A4_RRxk"
   },
   "outputs": [],
   "source": [
    "train_text_features = textual_model_int.predict(np.array(content_train_data))\n",
    "train_image_features = visual_model_int.predict(np.array(images_train_data))\n",
    "\n",
    "test_text_features = textual_model_int.predict(np.array(content_test_data))\n",
    "test_image_features = visual_model_int.predict(np.array(image_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSH0ZESA6T7j"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZRbsTu8BcTW"
   },
   "outputs": [],
   "source": [
    "images_test_df = pd.DataFrame(images_test)\n",
    "images_train_df = pd.DataFrame(images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZmKfEbMAyS2"
   },
   "outputs": [],
   "source": [
    "text_similarity = cosine_similarity(test_text_features, train_text_features)\n",
    "image_similarity = cosine_similarity(test_image_features, train_image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1NaVPKvVBIAN",
    "outputId": "acec75fe-2cc4-4351-c8bb-a56e1c83da17"
   },
   "outputs": [],
   "source": [
    "text_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GozjdkVUBMOb"
   },
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame(text_similarity)\n",
    "image_df = pd.DataFrame(image_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-yOSXc3BcuQ"
   },
   "outputs": [],
   "source": [
    "fused_similarity = text_similarity + image_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEujgxuxEgUV"
   },
   "outputs": [],
   "source": [
    "fused_df = pd.DataFrame(fused_similarity, index=images_test_df['image_path'], columns=images_train_df['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "4_OPZ7ylMI-K",
    "outputId": "f217fed7-6fdb-4975-acb8-303512f93513"
   },
   "outputs": [],
   "source": [
    "acc = 0\n",
    "K = 10\n",
    "count = 0\n",
    "\n",
    "for each_index in range(fused_df.shape[0]):\n",
    "  index_label = fused_df.iloc[each_index].name.rsplit('/', 2)[1]\n",
    "  labels = list(map(lambda x: x.rsplit('/', 2)[1], fused_df.iloc[each_index].sort_values().nlargest(K).index))\n",
    "  found_nums = np.count_nonzero(np.array(labels) == index_label)\n",
    "  acc += (found_nums / K)\n",
    "  # acc += int(index_label == labels[0])\n",
    "  # print('-----------------------------------------------------')\n",
    "  count += 1\n",
    "  # print(count)\n",
    "  if count > 0 and count % 100 == 0:\n",
    "      print(\"Done \", count)\n",
    "      print(\"Accuracy so far %g %%\" % (acc/count * 100))\n",
    "\n",
    "mean_accuracy = acc/fused_df.shape[0]\n",
    "print(\"\\nThe mean accuracy for top %d images is %g %%\" % (K, mean_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_HajmKq4gTCa"
   },
   "outputs": [],
   "source": [
    "acc /= fused_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6LJLc8ZOgbyH",
    "outputId": "da52f21a-f5ad-4cbc-c1e5-c73e6194f633"
   },
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3z4IPriXqXI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Fusion Model -Manuscript (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
